import { Octokit } from "@octokit/rest";
import { config } from "dotenv";
import fs from "fs-extra";
import { Parser } from "json2csv";

config();
const G = new Octokit({ auth: process.env.GITHUB_TOKEN });

const PER_PAGE = 30;
const STAR_BUCKETS = [">=1000", "100..999", "10..99", "<10"];
const AI_TOOLS = [
  "copilot",
  "chatgpt",
  "cursor",
  "gemini",
  "grok",
  "codewhisperer",
  "codeium",
  "deepseek",
];
const TERMS = [
  "created by",
  "generated by",
  "use",
  "using",
  "with",
  "powered by",
  "assisted by",
  "written with",
  "suggested by",
  "completed by",
  "AI-generated",
  "generated code",
  "generated with",
  "written using",
  "written by",
];
const LANGS = ["JavaScript", "TypeScript"];
const CACHE_FILE = "./progress_cache.json";
const CSV_FILE = "./ai_code_dataset2.csv";

// load or init
let state = await (async () => {
  if (await fs.pathExists(CACHE_FILE)) {
    try {
      const c = await fs.readJson(CACHE_FILE);
      c.seen = new Set(c.seen || []);
      return c;
    } catch (err) {
      console.warn(`‚ö†Ô∏è Could not parse ${CACHE_FILE}, starting fresh.`);
    }
  }
  return {
    i: 0,
    j: 0,
    k: 0,
    b: 0,
    p: 1,
    nextId: 1,
    results: [],
    seen: new Set(), // raw_url dedupe
  };
})();

// persist JSON state
async function saveState() {
  await fs.writeJson(
    CACHE_FILE,
    {
      i: state.i,
      j: state.j,
      k: state.k,
      b: state.b,
      p: state.p,
      nextId: state.nextId,
      results: state.results,
      seen: [...state.seen],
    },
    { spaces: 2 }
  );
}

// persist CSV (always write headers at least)
async function saveCsv() {
  // determine fields from first row or fallback
  const fields = state.results.length
    ? Object.keys(state.results[0])
    : [
        "id",
        "ai_tool",
        "phrase",
        "language",
        "stars_bucket",
        "repo",
        "file",
        "html_url",
        "raw_url",
        "stars",
        "forks",
        "desc",
        "loc",
        "snippet",
      ];
  const parser = new Parser({ fields });
  const csv = parser.parse(state.results);
  await fs.writeFile(CSV_FILE, csv);
}

// rate-limit guard
async function waitIfNeeded() {
  const {
    data: { rate },
  } = await G.rateLimit.get();
  if (rate.remaining < 5) {
    const ms = rate.reset * 1000 - Date.now();
    console.log(`‚è≥ Rate-limit low: sleeping ${Math.ceil(ms / 1000)}s`);
    await new Promise((r) => setTimeout(r, ms));
  }
}

async function crawl() {
  try {
    for (; state.i < AI_TOOLS.length; state.i++) {
      const tool = AI_TOOLS[state.i];
      for (; state.j < TERMS.length; state.j++) {
        const phrase = TERMS[state.j];
        for (; state.k < LANGS.length; state.k++) {
          const lang = LANGS[state.k];
          for (; state.b < STAR_BUCKETS.length; state.b++) {
            const stars = STAR_BUCKETS[state.b];
            const qbase = `"${phrase} ${tool}" language:${lang} stars:${stars}`;
            console.log(
              `üîç [${state.i},${state.j},${state.k},${state.b}] ${qbase}`
            );

            // page loop
            state.p = state.p || 1;
            while (true) {
              await waitIfNeeded();
              let res;
              try {
                res = await G.search.code({
                  q: qbase,
                  per_page: PER_PAGE,
                  page: state.p,
                });
              } catch (e) {
                if (e.status === 403) {
                  console.warn("üö¶ Rate-limit hit, backing off 60s");
                  await saveState();
                  await saveCsv();
                  await new Promise((r) => setTimeout(r, 60_000));
                  return crawl();
                }
                throw e;
              }
              const items = res.data.items;
              if (!items.length) break;

              for (const it of items) {
                if (!it.path.match(/\.(js|ts)$/)) continue;

                // de-dup on raw_url
                const raw_url = `https://raw.githubusercontent.com/${it.repository.full_name}/HEAD/${it.path}`;
                if (state.seen.has(raw_url)) continue;

                try {
                  const owner = it.repository.owner.login;
                  const repo = it.repository.name;
                  const [rinfo, finfo] = await Promise.all([
                    G.repos.get({ owner, repo }),
                    G.repos.getContent({ owner, repo, path: it.path }),
                  ]);
                  const raw = Buffer.from(
                    finfo.data.content,
                    "base64"
                  ).toString("utf8");
                  const row = {
                    id: state.nextId++,
                    ai_tool: tool,
                    phrase,
                    language: lang,
                    stars_bucket: stars,
                    repo: it.repository.full_name,
                    file: it.path,
                    html_url: it.html_url,
                    raw_url,
                    stars: rinfo.data.stargazers_count,
                    forks: rinfo.data.forks_count,
                    desc: rinfo.data.description || "",
                    loc: raw.split("\n").length,
                    snippet: raw.replace(/\r?\n|\r/g, " ").slice(0, 5000),
                  };
                  state.results.push(row);
                  state.seen.add(raw_url);
                  console.log(`  ‚ûï #${row.id} ${raw_url}`);
                } catch (err) {
                  console.warn(`  ‚ö†Ô∏è skip ${it.html_url}: ${err.message}`);
                }
              }

              state.p++;
              await saveState();
              await saveCsv();
            }

            // next stars bucket
            state.p = 1;
            state.b++;
            await saveState();
            await saveCsv();
          }
          state.b = 0;
        }
        state.k = 0;
      }
      state.j = 0;
    }

    // done
    await saveCsv();
    await fs.remove(CACHE_FILE);
    console.log("‚úÖ Crawl complete!");
  } catch (ex) {
    console.error("‚ùå Unexpected crash:", ex);
    await saveState();
    await saveCsv();
  }
}

crawl();
